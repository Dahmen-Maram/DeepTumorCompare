{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LZbU_3h3iIzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f270a6-f9ca-40ab-844d-f203db16953c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/8.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/8.9 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m7.5/8.9 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/813.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Colab Cell 2 â€” Installer paquets\n",
        "!pip install -q streamlit==1.22.0 pyngrok tensorflow Pillow numpy\n",
        "# (la version de tensorflow peut Ãªtre ajustÃ©e si nÃ©cessaire)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab Cell 5 â€” Lancer Streamlit en arriÃ¨re-plan et crÃ©er tunnel ngrok\n",
        "import os, time, subprocess, sys\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- CONFIG ---\n",
        "NGROK_AUTHTOKEN = \"2vdJFZExAVhUhUeOJZjhTHOLFhG_3noX2p3A3rDQ3KYjAKFgF\"  # remplace si nÃ©cessaire\n",
        "PORT = 8501\n",
        "LOGFILE = \"/content/streamlit.log\"\n",
        "\n",
        "# 1) Auth token ngrok\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "# 2) Kill d'anciennes instances (sÃ©curitaire)\n",
        "try:\n",
        "    !pkill -f streamlit\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "time.sleep(1)\n",
        "\n",
        "# 3) Lancer streamlit dans un subprocess (headless)\n",
        "cmd = [sys.executable, \"-m\", \"streamlit\", \"run\", \"app.py\", \"--server.port={}\".format(PORT), \"--server.headless=true\"]\n",
        "print(\"Lancement de Streamlit :\", \" \".join(cmd))\n",
        "f = open(LOGFILE, \"wb\")\n",
        "proc = subprocess.Popen(cmd, stdout=f, stderr=subprocess.STDOUT)\n",
        "\n",
        "# 4) Attendre un peu que streamlit dÃ©marre\n",
        "print(\"PID Streamlit:\", proc.pid)\n",
        "print(\"Attente de dÃ©marrage (10s)...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# 5) CrÃ©er tunnel ngrok\n",
        "public_url = ngrok.connect(PORT).public_url\n",
        "print(\"Streamlit public URL:\", public_url)\n",
        "print(\"Logs: \", LOGFILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raS-6nZSk8pW",
        "outputId": "d2757eaa-37a1-4b29-c338-fe83b3868841"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lancement de Streamlit : /usr/bin/python3 -m streamlit run app.py --server.port=8501 --server.headless=true\n",
            "PID Streamlit: 949\n",
            "Attente de dÃ©marrage (10s)...\n",
            "Streamlit public URL: https://c2c0c894df4c.ngrok-free.app\n",
            "Logs:  /content/streamlit.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok && fuser -k 8501/tcp && echo \"âœ… Nettoyage terminÃ©\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsWPHlRvlmTH",
        "outputId": "dced9998-0f64-431a-9952-05e332ae481d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-10-21T13:31:05+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-d0ebdb8c-9c05-4917-be74-6db7965c88ed acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras import layers, Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import io\n",
        "import traceback\n",
        "#VERSIONN FINAAALEEE\n",
        "# ----- CONFIG PATHS -----\n",
        "DENSENET_PATH = \"/content/drive/MyDrive/TumourDL/densenet_brain_tumor.h5\"\n",
        "VGG16_PATH = \"/content/drive/MyDrive/TumourDL/vgg16_brain_tumor.h5\"\n",
        "RESNET_PATH = \"/content/drive/MyDrive/Copie de resnet152v2_brain_tumor.h5\"\n",
        "# Ton fichier Xception â€” peut Ãªtre .keras (full model) ou un fichier de weights compatible\n",
        "XCEPTION_PATH = \"/content/drive/MyDrive/TumourDL/xception_brain_tumor.keras\"\n",
        "\n",
        "# ----- SETTINGS -----\n",
        "IMG_SIZE = (224, 224)\n",
        "XCEPTION_SIZE = (299, 299)\n",
        "CLASS_NAMES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "st.set_page_config(page_title=\"ğŸ§  Brain Tumor Classifier\", layout=\"wide\", page_icon=\"ğŸ§ \")\n",
        "st.title(\"ğŸ§  Brain Tumor Classifier â€” DenseNet121, VGG16, ResNet152V2 & Xception\")\n",
        "st.markdown(\"Upload an image, choose un modÃ¨le, et voir les prÃ©dictions et comparatifs.\")\n",
        "\n",
        "# ----- Robust Xception loader -----\n",
        "def try_load_xception(path, xception_size=XCEPTION_SIZE, num_classes=len(CLASS_NAMES)):\n",
        "    \"\"\"\n",
        "    1) Try load_model(path) â€” works if path is a full saved model (.keras or full .h5 model)\n",
        "    2) If that fails, rebuild Xception with input_shape=(299,299,3) and try model.load_weights(path)\n",
        "    \"\"\"\n",
        "    tb_full = tb_weights = \"\"\n",
        "    # 1) try load_model (full model)\n",
        "    try:\n",
        "        m = load_model(path)\n",
        "        return m\n",
        "    except Exception as e_full:\n",
        "        tb_full = traceback.format_exc()\n",
        "        # continue to try weights approach\n",
        "\n",
        "    # 2) try rebuild architecture and load weights\n",
        "    try:\n",
        "        base = Xception(weights=None, include_top=False, input_shape=(xception_size[0], xception_size[1], 3))\n",
        "        x = layers.GlobalAveragePooling2D()(base.output)\n",
        "        x = layers.Dense(128, activation='relu')(x)\n",
        "        x = layers.Dropout(0.1)(x)\n",
        "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "        model = Model(inputs=base.input, outputs=outputs)\n",
        "        model.load_weights(path)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "    except Exception as e_weights:\n",
        "        tb_weights = traceback.format_exc()\n",
        "\n",
        "    # both failed => raise informative RuntimeError\n",
        "    raise RuntimeError(\n",
        "        \"Both load_model() and rebuild+load_weights() failed for Xception.\\n\\n\"\n",
        "        f\"load_model() traceback:\\n{tb_full}\\n\\nrebuild+load_weights() traceback:\\n{tb_weights}\\n\\n\"\n",
        "        \"Causes possibles:\\n\"\n",
        "        \"- Le fichier n'est ni un modÃ¨le complet ni un fichier de poids compatibles.\\n\"\n",
        "        \"- Le fichier de poids a Ã©tÃ© sauvegardÃ© depuis une architecture diffÃ©rente.\\n\\n\"\n",
        "        \"Solutions recommandÃ©es:\\n\"\n",
        "        \"- Si tu as le script d'entraÃ®nement : `model.save('/path/xception_brain_tumor.keras')` (modÃ¨le complet).\\n\"\n",
        "        \"- Ou sauvegarde les poids avec `model.save_weights('/path/xception_weights.h5')` et fournis ces poids.\\n\"\n",
        "    )\n",
        "\n",
        "# ----- Cached loader -----\n",
        "@st.cache_resource(show_spinner=True)\n",
        "def load_model_cached(path, model_name=None):\n",
        "    if model_name == \"Xception\":\n",
        "        return try_load_xception(path)\n",
        "    return load_model(path)\n",
        "\n",
        "# ----- Load models -----\n",
        "dense_model = vgg_model = resnet_model = xception_model = None\n",
        "missing = []\n",
        "\n",
        "try:\n",
        "    dense_model = load_model_cached(DENSENET_PATH)\n",
        "except Exception as e:\n",
        "    missing.append((\"DenseNet121\", DENSENET_PATH, str(e)))\n",
        "\n",
        "try:\n",
        "    vgg_model = load_model_cached(VGG16_PATH)\n",
        "except Exception as e:\n",
        "    missing.append((\"VGG16\", VGG16_PATH, str(e)))\n",
        "\n",
        "try:\n",
        "    resnet_model = load_model_cached(RESNET_PATH)\n",
        "except Exception as e:\n",
        "    missing.append((\"ResNet152V2\", RESNET_PATH, str(e)))\n",
        "\n",
        "try:\n",
        "    xception_model = load_model_cached(XCEPTION_PATH, model_name=\"Xception\")\n",
        "except Exception as e:\n",
        "    missing.append((\"Xception\", XCEPTION_PATH, str(e)))\n",
        "\n",
        "if missing:\n",
        "    st.warning(\"Certains modÃ¨les n'ont pas pu Ãªtre chargÃ©s â€” vÃ©rifie les chemins et formats. DÃ©tails :\")\n",
        "    for name, path, err in missing:\n",
        "        st.markdown(f\"**{name}** â€” `{path}`\")\n",
        "        # show first lines of error to keep UI compact\n",
        "        first_lines = \"\\n\".join(str(err).splitlines()[:12])\n",
        "        st.code(first_lines, language=\"text\")\n",
        "        st.markdown(\"---\")\n",
        "    st.info(\"Si possible, fournis un modÃ¨le complet `.keras` ou un fichier de poids compatible et la mÃªme architecture.\")\n",
        "\n",
        "# ----- Preprocessing (adaptÃ©e au modÃ¨le choisi) -----\n",
        "def preprocess_image_for_model(img: Image.Image, model_name=None):\n",
        "    \"\"\"\n",
        "    Convertit en RGB, ajuste la taille en fonction du modÃ¨le (Xception=299, autres=224), normalise et ajoute batch dim.\n",
        "    \"\"\"\n",
        "    if img.mode != \"RGB\":\n",
        "        img = img.convert(\"RGB\")\n",
        "\n",
        "    if model_name == \"Xception\":\n",
        "        target_size = XCEPTION_SIZE\n",
        "    else:\n",
        "        target_size = IMG_SIZE\n",
        "\n",
        "    img = ImageOps.fit(img, target_size, method=Image.Resampling.LANCZOS)\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    return arr\n",
        "\n",
        "# ----- Prediction (utilise model_choice) -----\n",
        "def predict_model(model, img, model_name=None):\n",
        "    if model is None:\n",
        "        raise ValueError(\"Model is None â€” impossible de prÃ©dire.\")\n",
        "    x = preprocess_image_for_model(img, model_name=model_name)\n",
        "    preds = model.predict(x)\n",
        "    if preds.ndim == 2:\n",
        "        preds = preds[0]\n",
        "    top_idx = preds.argsort()[::-1]\n",
        "    return preds, top_idx\n",
        "\n",
        "# ----- Sidebar -----\n",
        "st.sidebar.header(\"âš™ï¸ Options\")\n",
        "show_topk = st.sidebar.slider(\"Afficher top-k probabilitÃ©s\", 1, len(CLASS_NAMES), 3)\n",
        "threshold = st.sidebar.slider(\"Seuil d'affichage (probabilitÃ© minimale)\", 0.0, 1.0, 0.0, 0.01)\n",
        "\n",
        "# ----- Upload + Prediction -----\n",
        "st.header(\"1ï¸âƒ£ Upload & PrÃ©diction\")\n",
        "uploaded_file = st.file_uploader(\"Choisis une image (jpg/png)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(uploaded_file.read()))\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur lors de la lecture de l'image : {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    col1, col2 = st.columns([1,1])\n",
        "    with col1:\n",
        "        st.image(image, caption=\"Image uploadÃ©e\", use_column_width=True)\n",
        "\n",
        "    with col2:\n",
        "        available_models = []\n",
        "        if dense_model is not None: available_models.append(\"DenseNet121\")\n",
        "        if vgg_model is not None: available_models.append(\"VGG16\")\n",
        "        if resnet_model is not None: available_models.append(\"ResNet152V2\")\n",
        "        if xception_model is not None: available_models.append(\"Xception\")\n",
        "\n",
        "        if not available_models:\n",
        "            st.error(\"Aucun modÃ¨le disponible â€” corrige les chemins ou formats et relance.\")\n",
        "        else:\n",
        "            model_choice = st.radio(\"Choisir le modÃ¨le pour la prÃ©diction\", available_models)\n",
        "            model = {\n",
        "                \"DenseNet121\": dense_model,\n",
        "                \"VGG16\": vgg_model,\n",
        "                \"ResNet152V2\": resnet_model,\n",
        "                \"Xception\": xception_model\n",
        "            }[model_choice]\n",
        "\n",
        "            preds, top_idx = predict_model(model, image, model_name=model_choice)\n",
        "\n",
        "            st.markdown(\"### Top probabilitÃ©s :\")\n",
        "            for i in range(show_topk):\n",
        "                idx = top_idx[i]\n",
        "                prob = float(preds[idx])\n",
        "                label = CLASS_NAMES[idx]\n",
        "                if prob >= threshold:\n",
        "                    st.success(f\"{i+1}. {label} â€” {prob*100:.2f}%\")\n",
        "                else:\n",
        "                    st.warning(f\"{i+1}. {label} â€” {prob*100:.2f}% (sous seuil)\")\n",
        "\n",
        "            best_i = top_idx[0]\n",
        "            best_prob = float(preds[best_i])\n",
        "            best_label = CLASS_NAMES[best_i]\n",
        "            if best_prob >= threshold:\n",
        "                st.success(f\"âœ… PrÃ©diction principale: {best_label} ({best_prob*100:.2f}%)\")\n",
        "            else:\n",
        "                st.warning(f\"âš ï¸ PrÃ©diction principale: {best_label} ({best_prob*100:.2f}%) sous le seuil\")\n",
        "\n",
        "# ----- Comparatif -----\n",
        "st.header(\"2ï¸âƒ£ Comparatif des modÃ¨les\")\n",
        "comparative_data = {\n",
        "    \"ModÃ¨le\": [\"DenseNet121\", \"VGG16\", \"ResNet152V2\", \"Xception\"],\n",
        "    \"Accuracy Test (%)\": [83.83, 88.25, 93.97, 70.00],\n",
        "    \"PrÃ©cision (%)\": [84.0, 88.5, 94.40, 68.70],\n",
        "    \"Recall (%)\": [83.0, 87.5, 93.97, 70.00]\n",
        "}\n",
        "df_compare = pd.DataFrame(comparative_data)\n",
        "st.table(df_compare)\n",
        "\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Made with Streamlit ğŸ§ \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJV9WS1pPaRI",
        "outputId": "73aa3587-bf26-4168-cd09-c8e0a162370e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    }
  ]
}